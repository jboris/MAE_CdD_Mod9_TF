##  README: Clasificaci贸n de Sentimiento en Rese帽as de Pel铆culas en Espa帽ol con BETO

***

###  Descripci贸n del Proyecto

Este proyecto consiste en la implementaci贸n de un modelo de **Clasificaci贸n de Sentimiento Binario** (Positivo/Negativo) aplicado a un conjunto de rese帽as de pel铆culas en espa帽ol. El objetivo principal es evaluar la eficacia de la t茅cnica de **Fine-Tuning** (ajuste fino) sobre el modelo pre-entrenado **BETO** (BERT en espa帽ol) para tareas de Procesamiento de Lenguaje Natural (PLN) en el contexto hispanohablante.

El desarrollo completo y la ejecuci贸n del modelo se realizan en un entorno de **Google Colaboratory**.

***

### 锔 Metodolog铆a

#### 1. Fuente de Datos
Se utiliz贸 el **IMDb Dataset of 50k Movie Reviews (Spanish)**, obtenido de la plataforma Kaggle. El conjunto de datos original conten铆a un desbalance considerable entre las clases de sentimiento.

#### 2. Preprocesamiento y Balanceo de Datos
* **An谩lisis de Desbalance:** Se identific贸 un desbalance de clases inicial con m谩s rese帽as clasificadas como "positivo" (6057) que como "negativo" (2808).
* **Estrategia de Balanceo:** Se aplic贸 la t茅cnica de **Submuestreo** (*Undersampling*) a la clase mayoritaria ("positivo") para igualar su n煤mero de muestras al de la clase minoritaria ("negativo"). El conjunto de datos balanceado resultante fue de **5616 muestras** (2808 de cada clase).

#### 3. Modelo de PLN (BETO)
Se emple贸 la arquitectura **BERT** (Bidirectional Encoder Representations from Transformers), espec铆ficamente la versi贸n pre-entrenada para el idioma espa帽ol: **BETO** (`dccuchile/bert-base-spanish-wwm-cased`).

El modelo fue ajustado (fine-tuned) para la tarea de **clasificaci贸n de secuencia** utilizando la librer铆a `transformers` de Hugging Face.

#### 4. Entrenamiento y Evaluaci贸n
El modelo fue entrenado utilizando el *Trainer* de la librer铆a `transformers` durante 2 茅pocas.

***

###  Resultados

El modelo de clasificaci贸n de sentimiento alcanz贸 los siguientes resultados en el conjunto de evaluaci贸n:

| M茅trica | Valor |
| :--- | :--- |
| **P茅rdida de Validaci贸n** (*Validation Loss*) | 0.4348 |
| **Precisi贸n Global** (*Accuracy*) | **0.880** (88.0%) |
| **AUC (rea Bajo la Curva ROC)** | **0.88** |

#### Reporte de Clasificaci贸n Detallado:

| Clase | Precisi贸n (*Precision*) | Recuperaci贸n (*Recall*) | Puntuaci贸n F1 (*F1-Score*) |
| :--- | :--- | :--- | :--- |
| **negativo** | 0.90 | 0.86 | 0.88 |
| **positivo** | 0.87 | 0.90 | 0.88 |

Los resultados demuestran un rendimiento robusto con una alta precisi贸n, indicando que el modelo BETO, tras el ajuste fino, es altamente efectivo para la clasificaci贸n de sentimiento en rese帽as de pel铆culas en espa帽ol.

***

###  Requisitos y Ejecuci贸n

Para reproducir este proyecto, es necesario un entorno que soporte la ejecuci贸n de notebooks de Jupyter/Colab y las siguientes librer铆as:

#### Librer铆as Principales:
* `transformers`
* `datasets`
* `opendatasets`
* `pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn` (para m茅tricas)

**Nota:** Se recomienda el uso de un entorno de ejecuci贸n con **GPU** (como la T4 utilizada en el proyecto) debido a los altos requerimientos computacionales del modelo BERT.

#### Pasos de Ejecuci贸n (en Google Colab):
1.  **Instalar dependencias:** Ejecutar las celdas que instalan `transformers` y `datasets`.
2.  **Descargar datos:** Ejecutar la celda de `od.download(dataset_url)` e introducir las credenciales de Kaggle cuando se solicite.
3.  **Ejecutar el *Notebook*:** Seguir secuencialmente las celdas para la carga, preprocesamiento de datos, configuraci贸n del modelo BETO, entrenamiento, y finalmente la evaluaci贸n de resultados.
